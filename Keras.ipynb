{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c619caf-ddd5-42a0-9949-597ad575fca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-803cbd083384>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# For running inference on the TF-Hub module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# For downloading the image.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_hub'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import shutil, os\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import yaml\n",
    "\n",
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "# For measuring the inference time.\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98629d1-236c-4c45-be2a-aa7751e7173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef display_image(image):\n",
    "  fig = plt.figure(figsize=(20, 15))\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image)\n",
    "\n",
    "\n",
    "def download_and_resize_image(url, new_width=256, new_height=256,\n",
    "                              display=False):\n",
    "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
    "  response = urlopen(url)\n",
    "  image_data = response.read()\n",
    "  image_data = BytesIO(image_data)\n",
    "  pil_image = Image.open(image_data)\n",
    "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
    "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
    "  print(\"Image downloaded to %s.\" % filename)\n",
    "  if display:\n",
    "    display_image(pil_image)\n",
    "  return filename\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = top + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                    (left + text_width, text_bottom)],\n",
    "                   fill=color)\n",
    "    draw.text((left + margin, text_bottom - text_height - margin),\n",
    "              display_str,\n",
    "              fill=\"black\",\n",
    "              font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
    "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "  colors = list(ImageColor.colormap.values())\n",
    "\n",
    "  try:\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
    "                              25)\n",
    "  except IOError:\n",
    "    #print(\"Font not found, using default font.\")\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  for i in range(min(boxes.shape[0], max_boxes)):\n",
    "    if scores[i] >= min_score:\n",
    "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                     int(100 * scores[i]))\n",
    "      color = colors[hash(class_names[i]) % len(colors)]\n",
    "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "      draw_bounding_box_on_image(\n",
    "          image_pil,\n",
    "          ymin,\n",
    "          xmin,\n",
    "          ymax,\n",
    "          xmax,\n",
    "          color,\n",
    "          font,\n",
    "          display_str_list=[display_str])\n",
    "      np.copyto(image, np.array(image_pil))\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3be5fb-6005-497d-b12c-7f1fd071bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(categories):\n",
    "    img_lst=[]\n",
    "    labels=[]\n",
    "    for index, category in enumerate(categories):\n",
    "        for image_name in os.listdir(fpath+\"/\"+category):\n",
    "            img = cv2.imread(fpath+\"/\"+category+\"/\"+image_name)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            img_array = Image.fromarray(img, 'RGB')\n",
    "            \n",
    "            #resize image to 227 x 227 because the input image resolution for AlexNet is 227 x 227\n",
    "            resized_img = img_array.resize((227, 227))\n",
    "            \n",
    "            img_lst.append(np.array(resized_img))\n",
    "            \n",
    "            labels.append(index)\n",
    "    return img_lst, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a92cd-18e4-48d3-a4ae-2f428666777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images_and_labels(categories)\n",
    "print(\"No. of images loaded = \",len(images),\"\\nNo. of labels loaded = \",len(labels))\n",
    "print(type(images),type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c92c4-6232-4794-860a-19af624a4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Images shape = \",images.shape,\"\\nLabels shape = \",labels.shape)\n",
    "print(type(images),type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6fb0e-03a6-4059-8981-869c83b211de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_rand_images(images, labels):\n",
    "    plt.figure(1 , figsize = (19 , 10))\n",
    "    n = 0 \n",
    "    for i in range(9):\n",
    "        n += 1 \n",
    "        r = np.random.randint(0 , images.shape[0] , 1)\n",
    "        \n",
    "        plt.subplot(3 , 3 , n)\n",
    "        plt.subplots_adjust(hspace = 0.3 , wspace = 0.3)\n",
    "        plt.imshow(images[r[0]])\n",
    "        \n",
    "        plt.title('Dog breed : {}'.format(labels[r[0]]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "display_rand_images(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9443b-e670-421b-9c84-9092e63f70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-step in data shuffling\n",
    "\n",
    "#get equally spaced numbers in a given range\n",
    "n = np.arange(images.shape[0])\n",
    "print(\"'n' values before shuffling = \",n)\n",
    "\n",
    "#shuffle all the equally spaced values in list 'n'\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(n)\n",
    "print(\"\\n'n' values after shuffling = \",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7080394b-9336-4a0e-ad3e-969cc5dcfb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-step in data shuffling\n",
    "\n",
    "#shuffle images and corresponding labels data in both the lists\n",
    "images = images[n]\n",
    "labels = labels[n]\n",
    "\n",
    "print(\"Images shape after shuffling = \",images.shape,\"\\nLabels shape after shuffling = \",labels.shape)\n",
    "ShuffleImages =  (3365, 227, 227, 3) \n",
    "ShuffleLabels =  (3365,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc155d1-07c1-46cb-ae40-84462e6a7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float32)\n",
    "labels = labels.astype(np.int32)\n",
    "images = images/255\n",
    "print(\"Images shape after normalization = \",images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1bada-2605-4c70-838a-2adb1d07f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_rand_images(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684bb043-888f-461a-b4e1-ee48582b38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state = random_seed)\n",
    "\n",
    "print(\"x_train shape = \",x_train.shape)\n",
    "print(\"y_train shape = \",y_train.shape)\n",
    "print(\"\\nx_test shape = \",x_test.shape)\n",
    "print(\"y_test shape = \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493c99d-5e05-4ee8-b299-593b6bb72c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_rand_images(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b509a1c-4dca-4632-b81a-6da699887676",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#1 conv layer\n",
    "model.add(Conv2D(filters=32,kernel_size=(11,11),strides=(4,4),activation=\"relu\",input_shape=(227,227,3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#2 conv layer\n",
    "model.add(Conv2D(filters=96,kernel_size=(5,5),strides=(1,1),activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "#3 conv layer\n",
    "model.add(Conv2D(filters=128,kernel_size=(1,1),strides=(1,1),activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "#4 conv layer\n",
    "model.add(Conv2D(filters=128,kernel_size=(1,1),strides=(1,1),activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "#5 conv layer\n",
    "model.add(Conv2D(filters=128,kernel_size=(1,1),strides=(1,1),activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "#1 dense layer\n",
    "model.add(Dense(192,activation=\"relu\"))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#2 dense layer\n",
    "model.add(Dense(192,activation=\"relu\"))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(20,activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c625b-1a7d-489a-bdd0-88587cab01db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947d8e8-c702-4804-8fa9-be4266224182",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef75386-8daa-4fe6-a895-c3cf72cfe46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(loss,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fbf460-6be8-4d11-ade6-b343245f2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff9970-b9ab-4af9-ac15-98d932dd21db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1 , figsize = (19 , 10))\n",
    "n = 0 \n",
    "\n",
    "for i in range(9):\n",
    "    n += 1 \n",
    "    r = np.random.randint( 0, x_test.shape[0], 1)\n",
    "    \n",
    "    plt.subplot(3, 3, n)\n",
    "    plt.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
    "    \n",
    "    plt.imshow(x_test[r[0]])\n",
    "    plt.title('Actual = {}, Predicted = {}'.format(y_test[r[0]] , y_test[r[0]]*pred[r[0]][y_test[r[0]]]) )\n",
    "    plt.xticks([]) , plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2b8ac-6f10-4f59-b777-f1378acc8668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
